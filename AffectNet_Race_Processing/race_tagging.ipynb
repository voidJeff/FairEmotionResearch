{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "246668dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "35e74687",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_filepath = pd.read_csv('val_fairface.csv')\n",
    "val_race_labels = pd.read_csv('val_set_race_tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6c9c0aeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>face_name_align</th>\n",
       "      <th>race</th>\n",
       "      <th>race4</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>race_scores_fair</th>\n",
       "      <th>race_scores_fair_4</th>\n",
       "      <th>gender_scores_fair</th>\n",
       "      <th>age_scores_fair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>detected_faces/4568_face0.jpg</td>\n",
       "      <td>Middle Eastern</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>50-59</td>\n",
       "      <td>[2.1768291e-01 1.4239328e-04 7.1944304e-02 5.4...</td>\n",
       "      <td>[9.8546553e-01 2.7187154e-04 2.5925806e-03 1.1...</td>\n",
       "      <td>[0.9977683  0.00223171]</td>\n",
       "      <td>[1.03524035e-04 6.51737500e-05 5.14067360e-04 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>detected_faces/4478_face0.jpg</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>20-29</td>\n",
       "      <td>[8.4236777e-01 2.4383063e-03 3.8513407e-02 2.7...</td>\n",
       "      <td>[0.9737646  0.00994458 0.00371436 0.01257646]</td>\n",
       "      <td>[1.7768645e-04 9.9982232e-01]</td>\n",
       "      <td>[9.0873023e-08 7.9405319e-05 4.4749342e-02 8.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>detected_faces/3680_face0.jpg</td>\n",
       "      <td>Middle Eastern</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>30-39</td>\n",
       "      <td>[9.6322842e-02 1.0394508e-04 8.7318001e-03 4.9...</td>\n",
       "      <td>[9.8704094e-01 8.1902806e-04 2.1604712e-03 9.9...</td>\n",
       "      <td>[9.9950171e-01 4.9830845e-04]</td>\n",
       "      <td>[4.8120575e-07 3.4811026e-06 9.5351937e-04 8.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>detected_faces/3517_face0.jpg</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>20-29</td>\n",
       "      <td>[4.0056580e-01 3.0805604e-04 5.6589925e-01 4.4...</td>\n",
       "      <td>[0.9123944  0.00995923 0.05633626 0.02131009]</td>\n",
       "      <td>[3.3785572e-04 9.9966210e-01]</td>\n",
       "      <td>[9.3651465e-08 3.9603107e-04 2.0330741e-01 7.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>detected_faces/3052_face0.jpg</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>20-29</td>\n",
       "      <td>[9.9764246e-01 5.8052287e-06 4.1569347e-04 3.5...</td>\n",
       "      <td>[9.9938327e-01 1.5375306e-04 4.3561461e-04 2.7...</td>\n",
       "      <td>[0.00827326 0.99172676]</td>\n",
       "      <td>[5.7399154e-07 1.2058897e-04 3.5707895e-02 6.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3989</th>\n",
       "      <td>detected_faces/2815_face0.jpg</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0-2</td>\n",
       "      <td>[9.4298667e-01 6.7099900e-05 3.6430648e-03 1.0...</td>\n",
       "      <td>[9.9915570e-01 1.1401189e-04 4.6327180e-04 2.6...</td>\n",
       "      <td>[0.6978695  0.30213052]</td>\n",
       "      <td>[9.9763316e-01 2.2303043e-03 7.3485994e-06 2.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3990</th>\n",
       "      <td>detected_faces/5319_face0.jpg</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>20-29</td>\n",
       "      <td>[5.7785457e-01 2.3699529e-04 9.9663585e-03 4.8...</td>\n",
       "      <td>[9.9765849e-01 2.1385393e-04 1.5424088e-03 5.8...</td>\n",
       "      <td>[0.99833655 0.00166348]</td>\n",
       "      <td>[1.11776750e-07 1.17308991e-04 1.09551385e-01 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3991</th>\n",
       "      <td>detected_faces/4667_face0.jpg</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0-2</td>\n",
       "      <td>[9.4282937e-01 9.4709168e-05 1.0409109e-02 2.1...</td>\n",
       "      <td>[9.9657118e-01 4.6331726e-04 1.2851665e-03 1.6...</td>\n",
       "      <td>[0.97190595 0.02809404]</td>\n",
       "      <td>[8.03962231e-01 1.67595521e-01 4.07164171e-03 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992</th>\n",
       "      <td>detected_faces/2865_face0.jpg</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>30-39</td>\n",
       "      <td>[9.8754233e-01 4.7955664e-06 7.0674147e-04 7.3...</td>\n",
       "      <td>[9.9548030e-01 2.9274950e-06 4.4952673e-03 2.1...</td>\n",
       "      <td>[9.9960011e-01 3.9988966e-04]</td>\n",
       "      <td>[5.9655504e-06 6.4635744e-05 6.6195382e-03 7.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3993</th>\n",
       "      <td>detected_faces/541_face0.jpg</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40-49</td>\n",
       "      <td>[0.26201123 0.02330458 0.4498638  0.00093397 0...</td>\n",
       "      <td>[0.73144984 0.07213818 0.00383566 0.19257638]</td>\n",
       "      <td>[9.9987060e-01 1.2938329e-04]</td>\n",
       "      <td>[6.9159003e-05 6.1492072e-05 5.1647844e-04 8.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3994 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    face_name_align             race  race4  gender    age  \\\n",
       "0     detected_faces/4568_face0.jpg   Middle Eastern  White    Male  50-59   \n",
       "1     detected_faces/4478_face0.jpg            White  White  Female  20-29   \n",
       "2     detected_faces/3680_face0.jpg   Middle Eastern  White    Male  30-39   \n",
       "3     detected_faces/3517_face0.jpg  Latino_Hispanic  White  Female  20-29   \n",
       "4     detected_faces/3052_face0.jpg            White  White  Female  20-29   \n",
       "...                             ...              ...    ...     ...    ...   \n",
       "3989  detected_faces/2815_face0.jpg            White  White    Male    0-2   \n",
       "3990  detected_faces/5319_face0.jpg            White  White    Male  20-29   \n",
       "3991  detected_faces/4667_face0.jpg            White  White    Male    0-2   \n",
       "3992  detected_faces/2865_face0.jpg            White  White    Male  30-39   \n",
       "3993   detected_faces/541_face0.jpg  Latino_Hispanic  White    Male  40-49   \n",
       "\n",
       "                                       race_scores_fair  \\\n",
       "0     [2.1768291e-01 1.4239328e-04 7.1944304e-02 5.4...   \n",
       "1     [8.4236777e-01 2.4383063e-03 3.8513407e-02 2.7...   \n",
       "2     [9.6322842e-02 1.0394508e-04 8.7318001e-03 4.9...   \n",
       "3     [4.0056580e-01 3.0805604e-04 5.6589925e-01 4.4...   \n",
       "4     [9.9764246e-01 5.8052287e-06 4.1569347e-04 3.5...   \n",
       "...                                                 ...   \n",
       "3989  [9.4298667e-01 6.7099900e-05 3.6430648e-03 1.0...   \n",
       "3990  [5.7785457e-01 2.3699529e-04 9.9663585e-03 4.8...   \n",
       "3991  [9.4282937e-01 9.4709168e-05 1.0409109e-02 2.1...   \n",
       "3992  [9.8754233e-01 4.7955664e-06 7.0674147e-04 7.3...   \n",
       "3993  [0.26201123 0.02330458 0.4498638  0.00093397 0...   \n",
       "\n",
       "                                     race_scores_fair_4  \\\n",
       "0     [9.8546553e-01 2.7187154e-04 2.5925806e-03 1.1...   \n",
       "1         [0.9737646  0.00994458 0.00371436 0.01257646]   \n",
       "2     [9.8704094e-01 8.1902806e-04 2.1604712e-03 9.9...   \n",
       "3         [0.9123944  0.00995923 0.05633626 0.02131009]   \n",
       "4     [9.9938327e-01 1.5375306e-04 4.3561461e-04 2.7...   \n",
       "...                                                 ...   \n",
       "3989  [9.9915570e-01 1.1401189e-04 4.6327180e-04 2.6...   \n",
       "3990  [9.9765849e-01 2.1385393e-04 1.5424088e-03 5.8...   \n",
       "3991  [9.9657118e-01 4.6331726e-04 1.2851665e-03 1.6...   \n",
       "3992  [9.9548030e-01 2.9274950e-06 4.4952673e-03 2.1...   \n",
       "3993      [0.73144984 0.07213818 0.00383566 0.19257638]   \n",
       "\n",
       "                 gender_scores_fair  \\\n",
       "0           [0.9977683  0.00223171]   \n",
       "1     [1.7768645e-04 9.9982232e-01]   \n",
       "2     [9.9950171e-01 4.9830845e-04]   \n",
       "3     [3.3785572e-04 9.9966210e-01]   \n",
       "4           [0.00827326 0.99172676]   \n",
       "...                             ...   \n",
       "3989        [0.6978695  0.30213052]   \n",
       "3990        [0.99833655 0.00166348]   \n",
       "3991        [0.97190595 0.02809404]   \n",
       "3992  [9.9960011e-01 3.9988966e-04]   \n",
       "3993  [9.9987060e-01 1.2938329e-04]   \n",
       "\n",
       "                                        age_scores_fair  \n",
       "0     [1.03524035e-04 6.51737500e-05 5.14067360e-04 ...  \n",
       "1     [9.0873023e-08 7.9405319e-05 4.4749342e-02 8.2...  \n",
       "2     [4.8120575e-07 3.4811026e-06 9.5351937e-04 8.0...  \n",
       "3     [9.3651465e-08 3.9603107e-04 2.0330741e-01 7.0...  \n",
       "4     [5.7399154e-07 1.2058897e-04 3.5707895e-02 6.9...  \n",
       "...                                                 ...  \n",
       "3989  [9.9763316e-01 2.2303043e-03 7.3485994e-06 2.0...  \n",
       "3990  [1.11776750e-07 1.17308991e-04 1.09551385e-01 ...  \n",
       "3991  [8.03962231e-01 1.67595521e-01 4.07164171e-03 ...  \n",
       "3992  [5.9655504e-06 6.4635744e-05 6.6195382e-03 7.8...  \n",
       "3993  [6.9159003e-05 6.1492072e-05 5.1647844e-04 8.0...  \n",
       "\n",
       "[3994 rows x 9 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_race_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f78fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_filepath['id'] = val_filepath['img_path'].str.extract(r'.*/(\\d{1}|\\d{2}|\\d{3}|\\d{4}|\\d{5})\\..*')\n",
    "val_race_labels['id']=val_race_labels['face_name_align'].str.extract(r'.*/(\\d{1}|\\d{2}|\\d{3}|\\d{4}|\\d{5})_.*')\n",
    "val_race_labels = val_race_labels.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3be94e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining\n",
    "val_filepath = val_filepath.join(val_race_labels.groupby('id').agg({'race': lambda x: list(x)}), on = \"id\", how = \"left\")\n",
    "val_filepath = val_filepath.join(val_race_labels.groupby('id').agg({'race4': lambda x: list(x)}), on = \"id\", how = \"left\")\n",
    "val_filepath = val_filepath.join(val_race_labels.groupby('id').agg({'gender': lambda x: list(x)}), on = \"id\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "de686049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>id</th>\n",
       "      <th>race</th>\n",
       "      <th>race4</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../val_set/images/5486.jpg</td>\n",
       "      <td>5486</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[Male]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../val_set/images/3632.jpg</td>\n",
       "      <td>3632</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[Male]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../val_set/images/3167.jpg</td>\n",
       "      <td>3167</td>\n",
       "      <td>[Black]</td>\n",
       "      <td>[Black]</td>\n",
       "      <td>[Female]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../val_set/images/5183.jpg</td>\n",
       "      <td>5183</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[Male]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../val_set/images/4837.jpg</td>\n",
       "      <td>4837</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[Female]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>../val_set/images/2015.jpg</td>\n",
       "      <td>2015</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[Female]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>../val_set/images/1398.jpg</td>\n",
       "      <td>1398</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[Female]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>../val_set/images/1530.jpg</td>\n",
       "      <td>1530</td>\n",
       "      <td>[Middle Eastern]</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[Female]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>../val_set/images/2108.jpg</td>\n",
       "      <td>2108</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[Male]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>../val_set/images/2339.jpg</td>\n",
       "      <td>2339</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[Female]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3999 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        img_path    id              race    race4    gender\n",
       "0     ../val_set/images/5486.jpg  5486           [White]  [White]    [Male]\n",
       "1     ../val_set/images/3632.jpg  3632           [White]  [White]    [Male]\n",
       "2     ../val_set/images/3167.jpg  3167           [Black]  [Black]  [Female]\n",
       "3     ../val_set/images/5183.jpg  5183           [White]  [White]    [Male]\n",
       "4     ../val_set/images/4837.jpg  4837           [White]  [White]  [Female]\n",
       "...                          ...   ...               ...      ...       ...\n",
       "3994  ../val_set/images/2015.jpg  2015           [White]  [White]  [Female]\n",
       "3995  ../val_set/images/1398.jpg  1398           [White]  [White]  [Female]\n",
       "3996  ../val_set/images/1530.jpg  1530  [Middle Eastern]  [White]  [Female]\n",
       "3997  ../val_set/images/2108.jpg  2108           [White]  [White]    [Male]\n",
       "3998  ../val_set/images/2339.jpg  2339           [White]  [White]  [Female]\n",
       "\n",
       "[3999 rows x 5 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num obs we lose\n",
    "val_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e7e75409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 725, 2603, 3024], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to see if mult faces detected in a single image\n",
    "multi_label_ids = []\n",
    "for i, row in val_filepath.iterrows():\n",
    "    if type(row['race']) is list:\n",
    "        if len(row['race']) > 1:\n",
    "            multi_label_ids.append(row['id'])\n",
    "    else:\n",
    "        continue\n",
    "np.where(val_filepath['id'].isin(multi_label_ids))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "734f0a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>id</th>\n",
       "      <th>race</th>\n",
       "      <th>race4</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../val_set/images/5486.jpg</td>\n",
       "      <td>5486</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[Male]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../val_set/images/3632.jpg</td>\n",
       "      <td>3632</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[Male]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../val_set/images/3167.jpg</td>\n",
       "      <td>3167</td>\n",
       "      <td>[Black]</td>\n",
       "      <td>[Black]</td>\n",
       "      <td>[Female]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../val_set/images/5183.jpg</td>\n",
       "      <td>5183</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[Male]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../val_set/images/4837.jpg</td>\n",
       "      <td>4837</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[Female]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>../val_set/images/2015.jpg</td>\n",
       "      <td>2015</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[Female]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>../val_set/images/1398.jpg</td>\n",
       "      <td>1398</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[Female]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>../val_set/images/1530.jpg</td>\n",
       "      <td>1530</td>\n",
       "      <td>[Middle Eastern]</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[Female]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>../val_set/images/2108.jpg</td>\n",
       "      <td>2108</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[Male]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>../val_set/images/2339.jpg</td>\n",
       "      <td>2339</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[White]</td>\n",
       "      <td>[Female]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3999 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        img_path    id              race    race4    gender\n",
       "0     ../val_set/images/5486.jpg  5486           [White]  [White]    [Male]\n",
       "1     ../val_set/images/3632.jpg  3632           [White]  [White]    [Male]\n",
       "2     ../val_set/images/3167.jpg  3167           [Black]  [Black]  [Female]\n",
       "3     ../val_set/images/5183.jpg  5183           [White]  [White]    [Male]\n",
       "4     ../val_set/images/4837.jpg  4837           [White]  [White]  [Female]\n",
       "...                          ...   ...               ...      ...       ...\n",
       "3994  ../val_set/images/2015.jpg  2015           [White]  [White]  [Female]\n",
       "3995  ../val_set/images/1398.jpg  1398           [White]  [White]  [Female]\n",
       "3996  ../val_set/images/1530.jpg  1530  [Middle Eastern]  [White]  [Female]\n",
       "3997  ../val_set/images/2108.jpg  2108           [White]  [White]    [Male]\n",
       "3998  ../val_set/images/2339.jpg  2339           [White]  [White]  [Female]\n",
       "\n",
       "[3999 rows x 5 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_filepath.loc[np.where(val_filepath['id'].isin(multi_label_ids))[0], 'race'] = None\n",
    "val_filepath.loc[np.where(val_filepath['id'].isin(multi_label_ids))[0], 'race4'] = None\n",
    "val_filepath.loc[np.where(val_filepath['id'].isin(multi_label_ids))[0], 'gender'] = None\n",
    "\n",
    "val_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cf271de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>id</th>\n",
       "      <th>race</th>\n",
       "      <th>race4</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>../val_set/images/2455.jpg</td>\n",
       "      <td>2455</td>\n",
       "      <td>Mult</td>\n",
       "      <td>Mult</td>\n",
       "      <td>Mult</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       img_path    id  race race4 gender\n",
       "725  ../val_set/images/2455.jpg  2455  Mult  Mult   Mult"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_filepath[val_filepath['id'] == '2455']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2dfc1cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[White]              2757\n",
       "[Middle Eastern]      316\n",
       "[Latino_Hispanic]     288\n",
       "[Black]               281\n",
       "[East Asian]          204\n",
       "[Indian]               79\n",
       "[Southeast Asian]      58\n",
       "NaN                    13\n",
       "None                    3\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_filepath.race.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eb0bc39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-59a174198863>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_filepath['race'] = val_filepath['race'].str[0]\n",
      "<ipython-input-67-59a174198863>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_filepath['race4'] = val_filepath['race4'].str[0]\n",
      "<ipython-input-67-59a174198863>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_filepath['gender'] = val_filepath['gender'].str[0]\n"
     ]
    }
   ],
   "source": [
    "val_filepath = val_filepath.dropna()\n",
    "val_filepath['race'] = val_filepath['race'].str[0]\n",
    "val_filepath['race4'] = val_filepath['race4'].str[0]\n",
    "val_filepath['gender'] = val_filepath['gender'].str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f4712eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>id</th>\n",
       "      <th>race</th>\n",
       "      <th>race4</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../val_set/images/5486.jpg</td>\n",
       "      <td>5486</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../val_set/images/3632.jpg</td>\n",
       "      <td>3632</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../val_set/images/3167.jpg</td>\n",
       "      <td>3167</td>\n",
       "      <td>Black</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../val_set/images/5183.jpg</td>\n",
       "      <td>5183</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../val_set/images/4837.jpg</td>\n",
       "      <td>4837</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>../val_set/images/2015.jpg</td>\n",
       "      <td>2015</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>../val_set/images/1398.jpg</td>\n",
       "      <td>1398</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>../val_set/images/1530.jpg</td>\n",
       "      <td>1530</td>\n",
       "      <td>Middle Eastern</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>../val_set/images/2108.jpg</td>\n",
       "      <td>2108</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>../val_set/images/2339.jpg</td>\n",
       "      <td>2339</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3983 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        img_path    id            race  race4  gender\n",
       "0     ../val_set/images/5486.jpg  5486           White  White    Male\n",
       "1     ../val_set/images/3632.jpg  3632           White  White    Male\n",
       "2     ../val_set/images/3167.jpg  3167           Black  Black  Female\n",
       "3     ../val_set/images/5183.jpg  5183           White  White    Male\n",
       "4     ../val_set/images/4837.jpg  4837           White  White  Female\n",
       "...                          ...   ...             ...    ...     ...\n",
       "3994  ../val_set/images/2015.jpg  2015           White  White  Female\n",
       "3995  ../val_set/images/1398.jpg  1398           White  White  Female\n",
       "3996  ../val_set/images/1530.jpg  1530  Middle Eastern  White  Female\n",
       "3997  ../val_set/images/2108.jpg  2108           White  White    Male\n",
       "3998  ../val_set/images/2339.jpg  2339           White  White  Female\n",
       "\n",
       "[3983 rows x 5 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b2ccf974",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_filepath.to_csv('affectnet_val_filepath_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c3829c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((286988, 9), (286988, 9))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = []\n",
    "all_files = glob.glob(os.path.join(\"./\" , \"train_fairface_race_pred*.csv\"))\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "frame.shape, frame.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a6cf595a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../train_set/images/275643.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../train_set/images/155796.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../train_set/images/1262.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../train_set/images/92652.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../train_set/images/301876.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287646</th>\n",
       "      <td>../train_set/images/256119.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287647</th>\n",
       "      <td>../train_set/images/208039.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287648</th>\n",
       "      <td>../train_set/images/370243.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287649</th>\n",
       "      <td>../train_set/images/95746.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287650</th>\n",
       "      <td>../train_set/images/161371.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287651 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              img_path\n",
       "0       ../train_set/images/275643.jpg\n",
       "1       ../train_set/images/155796.jpg\n",
       "2         ../train_set/images/1262.jpg\n",
       "3        ../train_set/images/92652.jpg\n",
       "4       ../train_set/images/301876.jpg\n",
       "...                                ...\n",
       "287646  ../train_set/images/256119.jpg\n",
       "287647  ../train_set/images/208039.jpg\n",
       "287648  ../train_set/images/370243.jpg\n",
       "287649   ../train_set/images/95746.jpg\n",
       "287650  ../train_set/images/161371.jpg\n",
       "\n",
       "[287651 rows x 1 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filepath = pd.read_csv('train_fairface.csv')\n",
    "train_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d4b6b1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   404,    535,    542,   1358,   2101,   6172,   7878,   8729,\n",
       "        10650,  12813,  13009,  13190,  14570,  14683,  15146,  15367,\n",
       "        15393,  18094,  18936,  20038,  20062,  20886,  22584,  22669,\n",
       "        24736,  25619,  26328,  27639,  27752,  28153,  29888,  30055,\n",
       "        30524,  31725,  32338,  33081,  34514,  34522,  35831,  35980,\n",
       "        36154,  37215,  38108,  38372,  38456,  39192,  40470,  41564,\n",
       "        42000,  42170,  42281,  42882,  43244,  44900,  45360,  45556,\n",
       "        46091,  46611,  47250,  48778,  49606,  50038,  50175,  51125,\n",
       "        51475,  54870,  56780,  57519,  58882,  60017,  61003,  61587,\n",
       "        61893,  62032,  62363,  63639,  64927,  65116,  65589,  66747,\n",
       "        67938,  68361,  68667,  69848,  69963,  71556,  71864,  72137,\n",
       "        73220,  73335,  74672,  74952,  76273,  77152,  79015,  79067,\n",
       "        79721,  81123,  81408,  81739,  82917,  84573,  84594,  85226,\n",
       "        86376,  87593,  87923,  88315,  88398,  88752,  89880,  90408,\n",
       "        91195,  91409,  91775,  92202,  92459,  93615,  95180,  96376,\n",
       "        97547,  99395,  99923, 100126, 100813, 101030, 101035, 101490,\n",
       "       102085, 102106, 102435, 103378, 103463, 103663, 104715, 104975,\n",
       "       105795, 105873, 106430, 106488, 108197, 108496, 109199, 109278,\n",
       "       109483, 110771, 111577, 111727, 112226, 112890, 113250, 113379,\n",
       "       115212, 116589, 116643, 116948, 117875, 119058, 119679, 119728,\n",
       "       119805, 119916, 120155, 122770, 123129, 125006, 126998, 127550,\n",
       "       127914, 128053, 128235, 128633, 130499, 132234, 132240, 132526,\n",
       "       133450, 133663, 134220, 134339, 134798, 135354, 136485, 136639,\n",
       "       137412, 138070, 138180, 138998, 139381, 139791, 140494, 140691,\n",
       "       141849, 142002, 142232, 143222, 143487, 144961, 145618, 146341,\n",
       "       146930, 146981, 147607, 147740, 147932, 147994, 148934, 151230,\n",
       "       151645, 152816, 154169, 154778, 155247, 155754, 157551, 160738,\n",
       "       161466, 162522, 163496, 164675, 165818, 166611, 167981, 168224,\n",
       "       168661, 170953, 171211, 173990, 174303, 175226, 175235, 175236,\n",
       "       175796, 177040, 177123, 177874, 178345, 178713, 179916, 182573,\n",
       "       183842, 185595, 186442, 186750, 186970, 187176, 187321, 191642,\n",
       "       192301, 192460, 193001, 193342, 194616, 194984, 195854, 196377,\n",
       "       196565, 197272, 198218, 198432, 199001, 199034, 199147, 199229,\n",
       "       199334, 199666, 201172, 202134, 202369, 203050, 203222, 203443,\n",
       "       205875, 206885, 209808, 209913, 210447, 210841, 211577, 213260,\n",
       "       214815, 215023, 217641, 218524, 218999, 219510, 219934, 220709,\n",
       "       220879, 221493, 221851, 222324, 222784, 223615, 223806, 224178,\n",
       "       225234, 226036, 226632, 227829, 227984, 230116, 230121, 230700,\n",
       "       230850, 231721, 232416, 232525, 233014, 236159, 236472, 237921,\n",
       "       238200, 238878, 239752, 240150, 240581, 240728, 242510, 243384,\n",
       "       244033, 244868, 245198, 247174, 247531, 247714, 248145, 248860,\n",
       "       249826, 251171, 251536, 251807, 252480, 253195, 253341, 253804,\n",
       "       254289, 256198, 258212, 258521, 260311, 261698, 262346, 263849,\n",
       "       264257, 264662, 264904, 265968, 267936, 268010, 269023, 269453,\n",
       "       270694, 270805, 271684, 273205, 273275, 273374, 274387, 274436,\n",
       "       275217, 275548, 275997, 276516, 276660, 277150, 280982, 281142,\n",
       "       281361, 281571, 281633, 281728, 282010, 282875, 284424, 284779,\n",
       "       285845, 286376, 286892], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filepath['id'] = train_filepath['img_path'].str.extract(r'.*/(\\d{1}|\\d{2}|\\d{3}|\\d{4}|\\d{5}|\\d{6})\\..*')\n",
    "frame['id']=frame['face_name_align'].str.extract(r'.*/(\\d{1}|\\d{2}|\\d{3}|\\d{4}|\\d{5}|\\d{6})_.*')\n",
    "frame = frame.dropna()\n",
    "\n",
    "# joining\n",
    "train_filepath = train_filepath.join(frame.groupby('id').agg({'race': lambda x: list(x)}), on = \"id\", how = \"left\")\n",
    "train_filepath = train_filepath.join(frame.groupby('id').agg({'race4': lambda x: list(x)}), on = \"id\", how = \"left\")\n",
    "train_filepath = train_filepath.join(frame.groupby('id').agg({'gender': lambda x: list(x)}), on = \"id\", how = \"left\")\n",
    "\n",
    "# check to see if mult faces detected in a single image\n",
    "multi_label_ids = []\n",
    "for i, row in train_filepath.iterrows():\n",
    "    if type(row['race']) is list:\n",
    "        if len(row['race']) > 1:\n",
    "            multi_label_ids.append(row['id'])\n",
    "    else:\n",
    "        continue\n",
    "np.where(train_filepath['id'].isin(multi_label_ids))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e3623d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[White]              0.674282\n",
       "[Latino_Hispanic]    0.087179\n",
       "[Middle Eastern]     0.072042\n",
       "[Black]              0.071761\n",
       "[East Asian]         0.057952\n",
       "[Indian]             0.018119\n",
       "[Southeast Asian]    0.013676\n",
       "NaN                  0.003671\n",
       "None                 0.001318\n",
       "Name: race, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filepath.loc[np.where(train_filepath['id'].isin(multi_label_ids))[0], 'race'] = None\n",
    "train_filepath.loc[np.where(train_filepath['id'].isin(multi_label_ids))[0], 'race4'] = None\n",
    "train_filepath.loc[np.where(train_filepath['id'].isin(multi_label_ids))[0], 'gender'] = None\n",
    "\n",
    "train_filepath.race.value_counts(dropna=False) / train_filepath.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "76a6ce25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepath = train_filepath.dropna()\n",
    "train_filepath['race'] = train_filepath['race'].str[0]\n",
    "train_filepath['race4'] = train_filepath['race4'].str[0]\n",
    "train_filepath['gender'] = train_filepath['gender'].str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "86257e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepath.to_csv('affectnet_train_filepath_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "364695e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get expression label\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "annotations = glob.glob(os.path.join(\"../train_set/\", \"annotations\", \"*_exp.npy\"))\n",
    "\n",
    "image_nums = []\n",
    "labels = []\n",
    "for annotation in annotations:\n",
    "    image_num = re.findall(r'(\\d+)', str(annotation))[0]\n",
    "    label = np.load(annotation).item()\n",
    "\n",
    "    if label == '7':\n",
    "        continue\n",
    "\n",
    "    image_nums.append(image_num)\n",
    "    labels.append(label)\n",
    "\n",
    "df = pd.DataFrame({\"image_num\": image_nums, \"label\": labels})\n",
    "df.label = df.label.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d48c2511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# does an inner join, so we have less since train_filepath lost some \n",
    "# and annotation labels don't have label == 7\n",
    "train_filepath_new = train_filepath.merge(df, left_on = 'id', right_on = 'image_num')\n",
    "train_filepath_new.to_csv('affectnet_train_filepath_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d165d40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((286216, 5), (282479, 7), (283901, 2))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filepath.shape, train_filepath_new.shape, df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6752c64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_filepath_new.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8471d6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13018     0\n",
       "19397     0\n",
       "22071     0\n",
       "33397     3\n",
       "88169     2\n",
       "100390    2\n",
       "116706    1\n",
       "121775    1\n",
       "130832    3\n",
       "130887    0\n",
       "181743    1\n",
       "187741    0\n",
       "253156    1\n",
       "264472    1\n",
       "271239    1\n",
       "279351    2\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filepath_new = pd.read_csv('affectnet_train_filepath_full.csv')\n",
    "race_spec_filepath = train_filepath_new.loc[train_filepath_new['race'] == (\"White\"), :]\n",
    "\n",
    "samples = np.random.default_rng().choice(\n",
    "                race_spec_filepath.img_path,\n",
    "                size=16,\n",
    "                replace=False)\n",
    "\n",
    "race_spec_filepath.loc[race_spec_filepath.img_path.isin(samples),\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "73d59801",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = race_spec_filepath.loc[race_spec_filepath.img_path.isin(samples),\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "55a7519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join annotations for val\n",
    "annotations = glob.glob(os.path.join(\"../val_set/\", \"annotations\", \"*_exp.npy\"))\n",
    "\n",
    "image_nums = []\n",
    "labels = []\n",
    "for annotation in annotations:\n",
    "    image_num = re.findall(r'(\\d+)', str(annotation))[0]\n",
    "    label = np.load(annotation).item()\n",
    "\n",
    "    if label == '7':\n",
    "        continue\n",
    "\n",
    "    image_nums.append(image_num)\n",
    "    labels.append(label)\n",
    "\n",
    "df = pd.DataFrame({\"image_num\": image_nums, \"label\": labels})\n",
    "df.label = df.label.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "dfe9d487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0          0\n",
       " 1       1001\n",
       " 2       1002\n",
       " 3       1003\n",
       " 4       1007\n",
       "         ... \n",
       " 3495     994\n",
       " 3496     995\n",
       " 3497     996\n",
       " 3498     999\n",
       " 3499       9\n",
       " Name: image_num, Length: 3500, dtype: object,\n",
       " 0       5486\n",
       " 1       3632\n",
       " 2       3167\n",
       " 3       5183\n",
       " 4       4837\n",
       "         ... \n",
       " 3978    2015\n",
       " 3979    1398\n",
       " 3980    1530\n",
       " 3981    2108\n",
       " 3982    2339\n",
       " Name: id, Length: 3983, dtype: int64,\n",
       " 0         275643\n",
       " 1         155796\n",
       " 2           1262\n",
       " 3          92652\n",
       " 4         301876\n",
       "            ...  \n",
       " 287646    256119\n",
       " 287647    208039\n",
       " 287648    370243\n",
       " 287649     95746\n",
       " 287650    161371\n",
       " Name: id, Length: 286216, dtype: object)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3f5e7890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# does an inner join, so we have less since train_filepath lost some \n",
    "# and annotation labels don't have label == 7\n",
    "val_filepath = pd.read_csv('affectnet_val_filepath_full.csv')\n",
    "val_filepath.id = val_filepath.id.astype(str)\n",
    "val_filepath_new = val_filepath.merge(df, left_on = 'id', right_on = 'image_num')\n",
    "val_filepath_new.to_csv('affectnet_val_filepath_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12c93b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>img_path</th>\n",
       "      <th>id</th>\n",
       "      <th>race</th>\n",
       "      <th>race4</th>\n",
       "      <th>gender</th>\n",
       "      <th>image_num</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../val_set/images/5486.jpg</td>\n",
       "      <td>5486</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>5486</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>../val_set/images/3632.jpg</td>\n",
       "      <td>3632</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>3632</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>../val_set/images/3167.jpg</td>\n",
       "      <td>3167</td>\n",
       "      <td>Black</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>3167</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>../val_set/images/5183.jpg</td>\n",
       "      <td>5183</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>5183</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>../val_set/images/1539.jpg</td>\n",
       "      <td>1539</td>\n",
       "      <td>Southeast Asian</td>\n",
       "      <td>Indian</td>\n",
       "      <td>Male</td>\n",
       "      <td>1539</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3481</th>\n",
       "      <td>3481</td>\n",
       "      <td>3994</td>\n",
       "      <td>../val_set/images/2015.jpg</td>\n",
       "      <td>2015</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3482</th>\n",
       "      <td>3482</td>\n",
       "      <td>3995</td>\n",
       "      <td>../val_set/images/1398.jpg</td>\n",
       "      <td>1398</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>1398</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>3483</td>\n",
       "      <td>3996</td>\n",
       "      <td>../val_set/images/1530.jpg</td>\n",
       "      <td>1530</td>\n",
       "      <td>Middle Eastern</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>1530</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>3484</td>\n",
       "      <td>3997</td>\n",
       "      <td>../val_set/images/2108.jpg</td>\n",
       "      <td>2108</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>3485</td>\n",
       "      <td>3998</td>\n",
       "      <td>../val_set/images/2339.jpg</td>\n",
       "      <td>2339</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>2339</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3486 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.1  Unnamed: 0                    img_path    id  \\\n",
       "0                0           0  ../val_set/images/5486.jpg  5486   \n",
       "1                1           1  ../val_set/images/3632.jpg  3632   \n",
       "2                2           2  ../val_set/images/3167.jpg  3167   \n",
       "3                3           3  ../val_set/images/5183.jpg  5183   \n",
       "4                4           6  ../val_set/images/1539.jpg  1539   \n",
       "...            ...         ...                         ...   ...   \n",
       "3481          3481        3994  ../val_set/images/2015.jpg  2015   \n",
       "3482          3482        3995  ../val_set/images/1398.jpg  1398   \n",
       "3483          3483        3996  ../val_set/images/1530.jpg  1530   \n",
       "3484          3484        3997  ../val_set/images/2108.jpg  2108   \n",
       "3485          3485        3998  ../val_set/images/2339.jpg  2339   \n",
       "\n",
       "                 race   race4  gender  image_num  label  \n",
       "0               White   White    Male       5486      5  \n",
       "1               White   White    Male       3632      3  \n",
       "2               Black   Black  Female       3167      3  \n",
       "3               White   White    Male       5183      1  \n",
       "4     Southeast Asian  Indian    Male       1539      6  \n",
       "...               ...     ...     ...        ...    ...  \n",
       "3481            White   White  Female       2015      1  \n",
       "3482            White   White  Female       1398      3  \n",
       "3483   Middle Eastern   White  Female       1530      3  \n",
       "3484            White   White    Male       2108      0  \n",
       "3485            White   White  Female       2339      6  \n",
       "\n",
       "[3486 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_filepath = pd.read_csv('affectnet_val_filepath_full.csv')\n",
    "val_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c5398c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
